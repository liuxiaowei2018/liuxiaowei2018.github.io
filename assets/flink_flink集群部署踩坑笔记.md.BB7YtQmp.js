import{_ as s,c as a,o as i,a4 as n}from"./chunks/framework.PLIGnzYk.js";const b=JSON.parse('{"title":"Flink集群部署踩坑笔记","description":"","frontmatter":{},"headers":[],"relativePath":"flink/flink集群部署踩坑笔记.md","filePath":"flink/flink集群部署踩坑笔记.md","lastUpdated":1727837951000}'),e={name:"flink/flink集群部署踩坑笔记.md"},t=n(`<h1 id="flink集群部署踩坑笔记" tabindex="-1">Flink集群部署踩坑笔记 <a class="header-anchor" href="#flink集群部署踩坑笔记" aria-label="Permalink to &quot;Flink集群部署踩坑笔记&quot;">​</a></h1><h2 id="集群搭建" tabindex="-1">集群搭建 <a class="header-anchor" href="#集群搭建" aria-label="Permalink to &quot;集群搭建&quot;">​</a></h2><h3 id="前置集群" tabindex="-1">前置集群 <a class="header-anchor" href="#前置集群" aria-label="Permalink to &quot;前置集群&quot;">​</a></h3><table tabindex="0"><thead><tr><th><strong>角色</strong></th><th>配置</th><th><strong>IP</strong></th></tr></thead><tbody><tr><td>hadoop102</td><td>4核 8G 40G</td><td>192.168.10.102</td></tr><tr><td>hadoop103</td><td>4核 8G 40G</td><td>192.168.10.103</td></tr><tr><td>hadoop104</td><td>4核 8G 40G</td><td>192.168.10.104</td></tr></tbody></table><h4 id="集群角色" tabindex="-1">集群角色 <a class="header-anchor" href="#集群角色" aria-label="Permalink to &quot;集群角色&quot;">​</a></h4><table tabindex="0"><thead><tr><th>节点服务器</th><th>hadoop102</th><th>hadoop103</th><th>hadoop104</th></tr></thead><tbody><tr><td>角色</td><td>JobManager<br>TaskManager</td><td>TaskManager</td><td>TaskManager</td></tr></tbody></table><h3 id="安装部署" tabindex="-1">安装部署 <a class="header-anchor" href="#安装部署" aria-label="Permalink to &quot;安装部署&quot;">​</a></h3><h4 id="集群配置" tabindex="-1">集群配置 <a class="header-anchor" href="#集群配置" aria-label="Permalink to &quot;集群配置&quot;">​</a></h4><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[liu@hadoop102 software]$ tar -zxvf flink-1.17.0-bin-scala_2.12.tgz -C /opt/module/</span></span></code></pre></div><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>cd /opt/module/flink-1.17.0/conf</span></span></code></pre></div><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 指定hadoop102节点服务器为JobManager </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[liu@hadoop102 conf]$ vim flink-conf.yaml</span></span></code></pre></div><div class="language-yaml vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">yaml</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># JobManager节点地址.</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">jobmanager.rpc.address</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">hadoop102</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">jobmanager.bind-host</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.0.0.0</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">rest.address</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">hadoop102</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">rest.bind-address</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.0.0.0</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># TaskManager节点地址.需要配置为当前机器名</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">taskmanager.bind-host</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.0.0.0</span></span>
<span class="line"><span style="--shiki-light:#22863A;--shiki-dark:#85E89D;">taskmanager.host</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">hadoop102</span></span></code></pre></div><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 指定hadoop102、hadoop103和hadoop104为TaskManager</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[liu@hadoop102 conf]$ vim workers</span></span></code></pre></div><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>hadoop102</span></span>
<span class="line"><span>hadoop103</span></span>
<span class="line"><span>hadoop104</span></span></code></pre></div><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">vim</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> masters</span></span></code></pre></div><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>hadoop102:8081</span></span></code></pre></div><p>在 flink-conf.yaml 文件中还可以对集群中的JobManager和TaskManager组件进行优化配置，主要配置项如下：</p><ul><li>jobmanager.memory.process.size：对JobManager进程可使用到的全部内存进行配置，包括JVM元空间和其他开销，默认为1600M，可以根据集群规模进行适当调整。</li><li>taskmanager.memory.process.size：对TaskManager进程可使用到的全部内存进行配置，包括JVM元空间和其他开销，默认为1728M，可以根据集群规模进行适当调整。</li><li>taskmanager.numberOfTaskSlots：对每个TaskManager能够分配的Slot数量进行配置，默认为1，可根据TaskManager所在的机器能够提供给Flink的CPU数量决定。所谓Slot就是TaskManager中具体运行一个任务所分配的计算资源。</li><li>parallelism.default：Flink任务执行的并行度，默认为1。优先级低于代码中进行的并行度配置和任务提交时使用参数指定的并行度数量。</li></ul><h4 id="分发集群" tabindex="-1">分发集群 <a class="header-anchor" href="#分发集群" aria-label="Permalink to &quot;分发集群&quot;">​</a></h4><p>配置修改完毕后，将Flink安装目录发给另外两个节点服务器。</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[liu@hadoop102 module]$ xsync flink-1.17.0/</span></span></code></pre></div><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 修改hadoop103 TaskManager节点地址.需要配置为当前机器名</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[liu@hadoop103 conf]$ vim flink-conf.yaml</span></span></code></pre></div><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">taskmanager.host:</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop103</span></span></code></pre></div><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 修改hadoop104 TaskManager节点地址.需要配置为当前机器名</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[liu@hadoop104 conf]$ vim flink-conf.yaml</span></span></code></pre></div><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">taskmanager.host:</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop104</span></span></code></pre></div><h4 id="启动flink集群" tabindex="-1">启动Flink集群 <a class="header-anchor" href="#启动flink集群" aria-label="Permalink to &quot;启动Flink集群&quot;">​</a></h4><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[liu@hadoop102 flink-1.17.0]$ bin/start-cluster.sh</span></span></code></pre></div><blockquote><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[liu@hadoop102 flink-1.17.0]$ jpsall </span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">===============</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop102</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> ===============</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">4453</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> StandaloneSessionClusterEntrypoint</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">4458</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> TaskManagerRunner</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">4533</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> Jps</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">===============</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop103</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> ===============</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">2872</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> TaskManagerRunner</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">2941</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> Jps</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">===============</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop104</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> ===============</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">2948</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> Jps</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">2876</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> TaskManagerRunner</span></span></code></pre></div><p>访问 <a href="http://hadoop102:8081" target="_blank" rel="noreferrer">http://hadoop102:8081</a> 对flink集群和任务进行监控管理。</p></blockquote><h3 id="yarn运行模式" tabindex="-1">YARN运行模式 <a class="header-anchor" href="#yarn运行模式" aria-label="Permalink to &quot;YARN运行模式&quot;">​</a></h3><p>客户端把 Flink应用 提交给 Yarn 的ResourceManager，Yarn 的 ResourceManager 会向Yarn的 NodeManager 申请容</p><p>器。在这些容器上，Flink会部署JobManager和TaskManager的实例，从而启动集群。Flink会根据运行在JobManger</p><p>上的作业所需要的Slot数量动态分配TaskManager资源。</p><h4 id="hadoop集群基础" tabindex="-1">Hadoop集群基础 <a class="header-anchor" href="#hadoop集群基础" aria-label="Permalink to &quot;Hadoop集群基础&quot;">​</a></h4><p>（1）配置环境变量，增加环境变量配置如下：</p><div class="language-ba vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">ba</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>$ sudo vim /etc/profile.d/my_env.sh</span></span></code></pre></div><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>HADOOP_HOME=/opt/module/hadoop-3.3.4</span></span>
<span class="line"><span>export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span></span>
<span class="line"><span>export HADOOP_CONF_DIR=\${HADOOP_HOME}/etc/hadoop</span></span>
<span class="line"><span>export HADOOP_CLASSPATH=\`hadoop classpath\`</span></span></code></pre></div><p>（2）启动Hadoop集群，包括HDFS和YARN。</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[liu@hadoop102 hadoop-3.3.4]$ start-dfs.sh</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[liu@hadoop103 hadoop-3.3.4]$ start-yarn.sh</span></span></code></pre></div><p>（3）在hadoop102中执行以下命令启动netcat。</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[liu@hadoop102 flink-1.17.0]$ nc -lk 7777</span></span></code></pre></div><h4 id="会话模式部署" tabindex="-1">会话模式部署 <a class="header-anchor" href="#会话模式部署" aria-label="Permalink to &quot;会话模式部署&quot;">​</a></h4><p>YARN的会话模式与独立集群略有不同，需要首先申请一个YARN会话（YARN Session）来启动Flink集群。具体步骤如下：</p><p>（1）启动Hadoop集群（HDFS、YARN）。</p><p>（2）执行脚本命令向YARN集群申请资源，开启一个YARN会话，启动Flink集群。</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[liu@hadoop102 flink-1.17.0]$ bin/yarn-session.sh -nm test</span></span></code></pre></div><blockquote><p>可用参数解读：</p><ul><li>-d：分离模式，如果你不想让Flink YARN客户端一直前台运行，可以使用这个参数，即使关掉当前对话窗口，YARN session也可以后台运行。</li><li>-jm（--jobManagerMemory）：配置JobManager所需内存，默认单位MB。</li><li>-nm（--name）：配置在YARN UI界面上显示的任务名。</li><li>-qu（--queue）：指定YARN队列名。</li><li>-tm（--taskManager）：配置每个TaskManager所使用内存。</li></ul><p><code>注意</code>：Flink1.11.0版本不再使用-n参数和-s参数分别指定TaskManager数量和slot数量，YARN会按照需求动态分</p><p>配TaskManager和slot。所以从这个意义上讲，YARN的会话模式也不会把集群资源固定，同样是动态分配的。</p></blockquote><p>YARN Session启动之后会给出一个Web UI地址以及一个YARN application ID，如下所示，用户可以通过Web UI或者命</p><p>令行两种方式提交作业。</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>2024-09-17 15:20:52,711 INFO  org.apache.flink.yarn.YarnClusterDescriptor                  [] - Found Web Interface hadoop104:40825 of application &#39;application_1668668287070_0001&#39;.</span></span>
<span class="line"><span>JobManager Web Interface: http://hadoop104:40825</span></span></code></pre></div><h3 id="历史服务器" tabindex="-1">历史服务器 <a class="header-anchor" href="#历史服务器" aria-label="Permalink to &quot;历史服务器&quot;">​</a></h3><p>1）创建存储目录</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">hadoop</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> fs</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -mkdir</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -p</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> /logs/flink-job</span></span></code></pre></div><p>2）在 flink-config.yaml中添加如下配置</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">jobmanager.archive.fs.dir:</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hdfs://hadoop102:8020/logs/flink-job</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">historyserver.web.address:</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hadoop102</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">historyserver.web.port:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 8082</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">historyserver.archive.fs.dir:</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> hdfs://hadoop102:8020/logs/flink-job</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">historyserver.archive.fs.refresh-interval:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 5000</span></span></code></pre></div><p>3）启动历史服务器</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">bin/historyserver.sh</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> start</span></span></code></pre></div><p>4）停止历史服务器</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">bin/historyserver.sh</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> stop</span></span></code></pre></div><p>5）在浏览器地址栏输入：<a href="http://hadoop102:8082" target="_blank" rel="noreferrer">http://hadoop102:8082</a> 查看已经停止的 job 的统计信息</p>`,59),p=[t];function l(h,o,d,k,r,c){return i(),a("div",null,p)}const u=s(e,[["render",l]]);export{b as __pageData,u as default};
