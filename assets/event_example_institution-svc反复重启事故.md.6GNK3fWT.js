import{_ as a,c as t,o as e,a4 as i}from"./chunks/framework.PLIGnzYk.js";const u=JSON.parse('{"title":"生产事件","description":"","frontmatter":{},"headers":[],"relativePath":"event/example/institution-svc反复重启事故.md","filePath":"event/example/institution-svc反复重启事故.md","lastUpdated":1727778851000}'),s={name:"event/example/institution-svc反复重启事故.md"},n=i('<h1 id="生产事件" tabindex="-1">生产事件 <a class="header-anchor" href="#生产事件" aria-label="Permalink to &quot;生产事件&quot;">​</a></h1><nav class="table-of-contents"><ul><li><a href="#institution-svc-反复重启">institution-svc 反复重启</a><ul><li><a href="#_1-1、问题描述">1.1、问题描述</a></li><li><a href="#_1-2、问题定位">1.2、问题定位</a></li><li><a href="#_1-3、解决方案">1.3、解决方案</a></li></ul></li></ul></nav><h2 id="institution-svc-反复重启" tabindex="-1">institution-svc 反复重启 <a class="header-anchor" href="#institution-svc-反复重启" aria-label="Permalink to &quot;institution-svc 反复重启&quot;">​</a></h2><h3 id="_1-1、问题描述" tabindex="-1">1.1、问题描述 <a class="header-anchor" href="#_1-1、问题描述" aria-label="Permalink to &quot;1.1、问题描述&quot;">​</a></h3><p><img src="https://knowledge-2018.oss-cn-shanghai.aliyuncs.com/img/202410011809708.png" alt="image-20230621135148765"></p><blockquote><p>1.k8s pod mdm-institution-svc-latest-7ff8854b7b-5j4s2 从凌晨开始 反复 重启</p></blockquote><h3 id="_1-2、问题定位" tabindex="-1">1.2、问题定位 <a class="header-anchor" href="#_1-2、问题定位" aria-label="Permalink to &quot;1.2、问题定位&quot;">​</a></h3><p>1.通过告警查看 grafa 监控 查看服务 JVM</p><p><img src="https://knowledge-2018.oss-cn-shanghai.aliyuncs.com/img/202410011809094.png" alt="image-20230621142524374"></p><p><code>服务占用pod内存几乎打满</code></p><p>2.定位慢接口或接口请求</p><p>通过skyingwalking 发现 /departmentTrading/list 这个接口的请求相对较多</p><p><img src="https://knowledge-2018.oss-cn-shanghai.aliyuncs.com/img/202410011809832.png" alt="image-20230621142055398"></p><p>但接口响应是正常的</p><p>3.进入pod查看 jvm配置和 pod内存</p><p><img src="https://knowledge-2018.oss-cn-shanghai.aliyuncs.com/img/202410011809833.png" alt="image-20230621143048422"></p><p><img src="https://knowledge-2018.oss-cn-shanghai.aliyuncs.com/img/202410011810791.png" alt="image-20230621143256352"></p><p>分析一波GC 感觉也没什么问题</p><p>这样一看 似乎不是 jvm本身的问题，问题指向到运维K8s POD那边</p><p><img src="https://knowledge-2018.oss-cn-shanghai.aliyuncs.com/img/202410011810723.png" alt="image-20230621143538652"></p><p>CICD上看了一下这个服务的JVM配置</p><p><code>最小和最大堆内存 设置为 8G</code></p><p><img src="https://knowledge-2018.oss-cn-shanghai.aliyuncs.com/img/202410011810362.png" alt="image-20230621143948800"></p><p><code>JVM堆内存分配多了！</code></p><p><code>当jvm服务JVM内存+堆外内存 超过 POD内存 limit ，POD直接 kill 了</code></p><h3 id="_1-3、解决方案" tabindex="-1">1.3、解决方案 <a class="header-anchor" href="#_1-3、解决方案" aria-label="Permalink to &quot;1.3、解决方案&quot;">​</a></h3><p>最后重新合理分配一下 JVM 堆内存</p><blockquote><p>-Xms6144m -Xmx6144m</p></blockquote><p>重新滚动一下服务</p><p><img src="https://knowledge-2018.oss-cn-shanghai.aliyuncs.com/img/202410011810566.png" alt="image-20230621144531728"></p><p>监控正常 服务也没有再发生告警！</p><p><code>解决问题！</code></p><blockquote><p>堆外内存 是如何被使用的？[待续...]</p></blockquote>',33),o=[n];function c(p,l,m,h,r,d){return e(),t("div",null,o)}const _=a(s,[["render",c]]);export{u as __pageData,_ as default};
